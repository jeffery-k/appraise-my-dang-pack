{
  "text": "MAJOR SNOOZE WARNING\n\nThe general philosophy is to assume every accepted trade is a fair trade where both parties are offering the same value of cards as they are requesting. With this assumption we use an algorithmic approach to find the value of every card that would produce the fairest trades overall (fair being trades where the discrepancy in value exchanged is near 0).\n\nFirst I downloaded every trade conducted where the trade was accepted and at least one card was offered and at least one card was requested. I group the trades by month they took place. For the first month of trades I set the value of all cards to 1 and compute the net of square errors between all trades. That is to say the difference between the values traded squared for all trades summed up. Via Pythonâ€™s scipy.optimize library, I attempt to minimize this net error by algorithmically adjusting the values of every card. The values that create the smallest net squared errors are used as the value estimates for the cards for that month. This process is repeated for every month, using the previous card value estimates for initial calculations. Finally, all values were multiplied by 10,000.\n\nLimitations:\n\nBecause value estimates depend on trades executed, value estimates only exist for cards that were traded and they only exist during months the cards were traded. I made no attempt to group cards (even near identical cards), nor did I attempt to filter out blatantly unfair trades (aside from trades where one or both sides offered no cards at all). Personally I think it would have been more accurate to group trades by quarters (3 months) rather than single months, but alas my poor 6 year old laptop was not down to run those computations.\n\nAlso, and this is perhaps the most important limitation, there is no accounting for heart <3\n"
}